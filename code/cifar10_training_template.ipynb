{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67063d65",
   "metadata": {},
   "source": [
    "### Device Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e65d9405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "USE_GPU = True\n",
    "dtype = torch.float32 # We will be using float throughout this tutorial.\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss.\n",
    "print_every = 100\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a438ed21",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46c66a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:05<00:00, 33.1MB/s] \n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN = 49000\n",
    "\n",
    "# The torchvision.transforms package provides tools for preprocessing data\n",
    "# and for performing data augmentation; here we set up a transform to\n",
    "# preprocess the data by subtracting the mean RGB value and dividing by the\n",
    "# standard deviation of each RGB value; we've hardcoded the mean and std.\n",
    "CIFAR10_MEAN = [0.4914, 0.4822, 0.4465]\n",
    "CIFAR10_STD  = [0.2470, 0.2435, 0.2616]\n",
    "\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(CIFAR10_MEAN, CIFAR10_STD),\n",
    "    T.Lambda(torch.flatten)\n",
    "])\n",
    "\n",
    "# We set up a Dataset object for each split (train / val / test); Datasets load\n",
    "# training examples one at a time, so we wrap each Dataset in a DataLoader which\n",
    "# iterates through the Dataset and forms minibatches. We divide the CIFAR-10\n",
    "# training set into train and val sets by passing a Sampler object to the\n",
    "# DataLoader telling how it should sample from the underlying Dataset.\n",
    "cifar10_train = dset.CIFAR10('./data', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64,\n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('./data', train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64,\n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('./data', train=False, download=True,\n",
    "                            transform=transform)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44a8e474",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        # x: (N, 3, 32, 32) -> (N, 3072) \n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "class Unflatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        # x: (N, 3072) -> (N, 3, 32, 32)\n",
    "        return x.view(x.shape[0], 3, 32, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbee83b3",
   "metadata": {},
   "source": [
    "### Training/Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a67db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(loader, model, device=device):\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum().item()\n",
    "            num_samples += y.size(0)\n",
    "    return num_correct / num_samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aafee52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(loader, model, device=device):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9153defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(model, optimizer, epochs=1, print_every=100):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "\n",
    "    Tracks:\n",
    "      - per-iteration training loss\n",
    "      - per-iteration validation accuracy\n",
    "    Allows:\n",
    "      - early stop via Ctrl+C\n",
    "    Plots:\n",
    "      - loss vs iteration\n",
    "      - validation accuracy vs iteration\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)\n",
    "\n",
    "    history = {\n",
    "        \"iter\": [],\n",
    "        \"train_loss\": [],\n",
    "        \"val_acc\": [],\n",
    "    }\n",
    "\n",
    "    global_iter = 0\n",
    "\n",
    "    try:\n",
    "        for e in range(epochs):\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"Epoch {e + 1}/{epochs}\")\n",
    "            print(\"=\" * 60)\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            for t, (x, y) in enumerate(loader_train):\n",
    "                global_iter += 1\n",
    "\n",
    "                x = x.to(device=device, dtype=dtype)\n",
    "                y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "                scores = model(x)\n",
    "                loss = F.cross_entropy(scores, y)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if global_iter % print_every == 0:\n",
    "                    # Record train loss\n",
    "                    history[\"iter\"].append(global_iter)\n",
    "                    history[\"train_loss\"].append(loss.item())\n",
    "\n",
    "                    # Compute validation accuracy\n",
    "                    val_acc = compute_accuracy(loader_val, model)\n",
    "                    history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "                    print(f\"[Iter {global_iter}] loss = {loss.item():.4f}\")\n",
    "                    print(f\"   validation accuracy: {val_acc * 100:.2f}%\")\n",
    "\n",
    "            print()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n⚠️ Training interrupted by user. Plotting collected results...\\n\")\n",
    "\n",
    "    finally:\n",
    "        if len(history[\"iter\"]) > 0:\n",
    "            it = history[\"iter\"]\n",
    "            loss = history[\"train_loss\"]\n",
    "            acc  = [a * 100 for a in history[\"val_acc\"]]\n",
    "\n",
    "            plt.figure(figsize=(8, 5))\n",
    "\n",
    "            # ---- Left axis: Loss ----\n",
    "            ax1 = plt.gca()\n",
    "            ax1.plot(it, loss, color='tab:red', marker='o', label='Training Loss')\n",
    "            ax1.set_xlabel(\"Iteration\")\n",
    "            ax1.set_ylabel(\"Training Loss\", color='tab:red')\n",
    "            ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "            \n",
    "            # ---- Right axis: Accuracy ----\n",
    "            ax2 = ax1.twinx()\n",
    "            ax2.plot(it, acc, color='tab:blue', marker='o', label='Validation Accuracy')\n",
    "            ax2.set_ylabel(\"Validation Accuracy (%)\", color='tab:blue')\n",
    "            ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "            # ---- Title & Grid ----\n",
    "            plt.title(\"Training Loss & Validation Accuracy vs Iteration\")\n",
    "            ax1.grid(True)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "            print(\"No statistics collected; nothing to plot.\")\n",
    "\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "250ea7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer):\n",
    "    train(model, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7abb74",
   "metadata": {},
   "source": [
    "### Train model here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430baf0b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
